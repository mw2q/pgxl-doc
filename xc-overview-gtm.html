<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>GTM and Global Transaction Management</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"><LINK
REV="MADE"
HREF="mailto:pgsql-docs@postgresql.org"><LINK
REL="HOME"
TITLE="Postgres-XL 9.5alpha1 (Postgres-XL 9.5alpha1) Documentation"
HREF="index.html"><LINK
REL="UP"
TITLE="Overview of Postgres-XL Internals"
HREF="xc-overview.html"><LINK
REL="PREVIOUS"
TITLE="Postgres-XL Components"
HREF="xc-overview-components.html"><LINK
REL="NEXT"
TITLE="System Catalogs"
HREF="catalogs.html"><LINK
REL="STYLESHEET"
TYPE="text/css"
HREF="stylesheet.css"><META
HTTP-EQUIV="Content-Type"
CONTENT="text/html; charset=ISO-8859-1"><META
NAME="creation"
CONTENT="2015-09-22T19:50:57"></HEAD
><BODY
CLASS="SECT1"
><DIV
CLASS="NAVHEADER"
><TABLE
SUMMARY="Header navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="4"
ALIGN="center"
VALIGN="bottom"
><A
HREF="index.html"
>Postgres-XL 9.5alpha1 (Postgres-XL 9.5alpha1) Documentation</A
></TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
TITLE="Postgres-XL Components"
HREF="xc-overview-components.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="top"
><A
HREF="xc-overview.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="60%"
ALIGN="center"
VALIGN="bottom"
>Chapter 49. Overview of <SPAN
CLASS="PRODUCTNAME"
>Postgres-XL</SPAN
> Internals</TD
><TD
WIDTH="20%"
ALIGN="right"
VALIGN="top"
><A
TITLE="System Catalogs"
HREF="catalogs.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="XC-OVERVIEW-GTM"
>49.2. GTM and Global Transaction Management</A
></H1
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="XC-OVERVIEW-GTM-PGREVIEW"
>49.2.1. Review of <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> Transaction Management Internals</A
></H2
><P
>     In PostgreSQL, each transaction is given unique ID called
     transaction ID (or XID). XID is given in ascending order to
     distinguish which transaction is older/newer.
     <A
NAME="AEN102604"
HREF="#FTN.AEN102604"
><SPAN
CLASS="footnote"
>[1]</SPAN
></A
>
     When a transaction tries to read a tuple, 
     <A
NAME="AEN102606"
HREF="#FTN.AEN102606"
><SPAN
CLASS="footnote"
>[2]</SPAN
></A
>
     each tuple has a set of XIDs to indicate transactions which
     created and deleted the tuple. So if the target tuple is created
     by an active transaction, it is not committed or aborted and the
     transaction should ignore such tuple. In such way (in practice,
     this is done by versup module in PostgreSQL core), if we give
     each transaction a unique transaction Id throughout the system
     and maintain snapshot what transaction is active, not only in a
     single server but transaction in all the servers, we can maintain
     global consistent visibility of each tuple even when a server
     accepts new statement from other transactions running on the
     other server.
    </P
><P
>     These information is stored in "<TT
CLASS="VARNAME"
>xmin</TT
>" and
     "<TT
CLASS="VARNAME"
>xmax</TT
>" fields of each row of table. When
     we <TT
CLASS="COMMAND"
>INSERT</TT
> rows, <TT
CLASS="VARNAME"
>XID</TT
> of
     inserting transaction is recorded at xmin field. When we update
     rows of tables (with <TT
CLASS="COMMAND"
>UPDATE</TT
>
     or <TT
CLASS="COMMAND"
>DELETE</TT
> statement), PostgreSQL does not
     simply overwrite the old rows. Instead, PostgreSQL
     "<SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>marks</I
></SPAN
>" the old rows as
     "<SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>deleted</I
></SPAN
>" by writing updating
     transaction's <TT
CLASS="VARNAME"
>XID</TT
> to xmax field. In the case
     of <TT
CLASS="COMMAND"
>UPDATE</TT
> (just
     like <TT
CLASS="COMMAND"
>INSERT</TT
>), new rows are created whose xmin
     field is "<SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>marked</I
></SPAN
>"
     with <TT
CLASS="VARNAME"
>XID</TT
>s of the creating transaction.
    </P
><P
>     These "<TT
CLASS="VARNAME"
>xmin</TT
>" and "<TT
CLASS="VARNAME"
>xmax</TT
>" are
     used to determine which row is visible to a transaction. To do
     this, PostgreSQL needs a data to indicate what transactions are
     running, which is called the "<SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>snapshot</I
></SPAN
>".
    </P
><P
>     If the creating transaction is not running, visibility of each
     row depends upon the fact if the creating transaction was
     committed or aborted. Suppose a row of a table which was created
     by some transaction and is not deleted yet. If the creating
     transaction is running, such row is visible to the transaction
     which created the row, but not visible to other transactions.  If
     the creating transaction is not running and was committed the row
     is visible. If the transaction was aborted, this row is not
     visible.
    </P
><P
>     Therefore, PostgreSQL needs two kinds of information to determine
     "which transaction is running" and "if an old transaction was
     committed or aborted."
    </P
><P
>     The former information is obtained as
     "<SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>snapshot</I
></SPAN
>."  PostgreSQL maintains the latter
     information as "<TT
CLASS="FILENAME"
>CLOG</TT
>."
    </P
><P
>     PostgreSQL uses all these information to determine which row is
     visible to a given transaction.
    </P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="XC-OVERVIEW-GLOBAL-MVCC"
>49.2.2. Making Transaction Management Global</A
></H2
><P
>     In Postgres-XL, the following features of transaction management
     and visibility checking extracted out from the nodes and pulled 
     into the GTM.
    </P
><P
></P
><UL
><LI
><P
>       Assigning XID globally to transactions (GXID, Global
       Transaction ID). This can be done globally to identify each
       Transactions in the system.
      </P
></LI
><LI
><P
>       Providing snapshots. GTM collects all the transaction's status
       (running, committed, aborted etc.) to provide snapshots globally
       (global snapshot). Please note that each global snapshot
       includes <TT
CLASS="VARNAME"
>GXID</TT
> initiated by other
       Coordinators or Datanodes.  This is needed because some older
       transaction may visit new server after a while. In this case,
       if <TT
CLASS="VARNAME"
>GXID</TT
> of such a transaction is not
       included in the snapshot, this transaction may be regarded as
       "old enough" and uncommitted rows may be
       read. If <TT
CLASS="VARNAME"
>GXID</TT
> of such transaction is
       included in the snapshot from the beginning, such inconsistency
       does not take place.
      </P
></LI
></UL
><P
>     To do this, <SPAN
CLASS="PRODUCTNAME"
>Postgres-XL</SPAN
> introduced a dedicated component called
     GTM (Global Transaction Manager). GTM runs on one of the servers
     and provides unique and ordered transaction id to each transaction
     running on <SPAN
CLASS="PRODUCTNAME"
>Postgres-XL</SPAN
> servers. Because this is a globally unique
     ID, we call this <TT
CLASS="VARNAME"
>GXID</TT
> (Global Transaction Id).
    </P
><P
>     GTM receives <TT
CLASS="VARNAME"
>GXID</TT
> request from transactions
     and provide <TT
CLASS="VARNAME"
>GXID</TT
>. It also keeps track of all
     the transactions when it started and finished to generate
     snapshots used to control each tuple visibility. Because snapshots
     here is also a global property, it is called <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>Global
     Snapshot</I
></SPAN
>.
    </P
><P
>     As long as each transaction runs with a <TT
CLASS="VARNAME"
>GXID</TT
> and
     a Global Snapshot, it can maintain consistent visibility throughout
     the system and it is safe to run transactions in parallel in any
     servers.  On the other hand, a transaction, composed of multiple
     statements, can be executed using multiple servers maintaining
     database consistency.
    </P
><P
>     GTM provides Global Transaction Id to each transaction and keeps
     track of the status of all the transactions, whether it is
     running, committed or aborted, to calculate global snapshots to
     maintain tuple visibility.
    </P
><P
>     For this purpose, each transaction reports when it starts and
     ends, as well as when it issues <TT
CLASS="COMMAND"
>PREPARE</TT
>
     command in two-phase commit protocol.
    </P
><P
>     Each transaction requests snapshots according to the transaction
     isolation level as done in PostgreSQL. If the transaction
     isolation level is "<SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>read committed</I
></SPAN
>", then
     transaction will request a snapshot for each statement. If it is
     "<SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>serializable</I
></SPAN
>" transaction will request a
     snapshot at the beginning of transaction and reuse it thought the
     transaction.
    </P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="XC-OVERVIEW-GTM-PROXY"
>49.2.3. Improving GTM Performance</A
></H2
><P
>     Because GTM can be regarded as "serializing" all the transaction
     processing, people may think that GTM can be a performance
     bottleneck.
    </P
><P
>     In fact, GTM can limit the whole scalability. GTM should not be
     used in very slow network environment such as wide area
     network. GTM architecture is intended to be used with Gigabit
     local network.  It is encouraged to install Postgres-XL with a local
     Gigabit network with minimum latency, that is, use as few
     switches involved in the connection among GTM, Coordinator and
     Datanodes.
     In addition, consider putting all components on their own subnet
     if you have multiple network ports in the systems.
    </P
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="AEN102664"
>49.2.3.1. Primitive GTM Implementation</A
></H3
><P
>      Primitive GTM implementation can be done as follows:
     </P
><DIV
CLASS="PROCEDURE"
><OL
TYPE="1"
><LI
CLASS="STEP"
><P
>       The Coordinator backend is provided with a GTM client library to
       obtain GXID and snapshots and to report the transaction status.
      </P
></LI
><LI
CLASS="STEP"
><P
>       GTM opens a port to accept connections from each Coordinator and
       Datanode backend. When GTM accepts a connection, it creates a
       thread (GTM Thread) to handle requests to GTM from the connected
       Coordinator backend.
      </P
></LI
><LI
CLASS="STEP"
><P
>       GTM Thread receives each request, records it and
       sends <TT
CLASS="VARNAME"
>GXID</TT
>, <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>snapshot</I
></SPAN
>
       and other response to the Coordinator backend.
      </P
></LI
><LI
CLASS="STEP"
><P
>       They are repeated until the Coordinator backend requests
       disconnect.
      </P
></LI
></OL
></DIV
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="AEN102678"
>49.2.3.2. GTM Proxy Implementation</A
></H3
><P
>      Each transaction is issuing
      requests to GTM frequently.  We can collect them into single
      block of requests in each Coordinator to reduce the amount of
      interaction by using a <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>GTM-Proxy</I
></SPAN
>.
     </P
><P
>      In this configuration, each Coordinator and Datanode backend
      does not connect to GTM directly. Instead, we have GTM Proxy
      between GTM and Coordinator backend to group multiple requests
      and responses. GTM Proxy, like GTM explained in the previous
      sections, accepts connections from the Coordinator
      backend. However, it does not create new thread. The following
      paragraphs explains how GTM Proxy is initialized and how it
      handles requests from Coordinator backends.
     </P
><P
>      GTM Proxy, as well as GTM, is initialized as follows:
     </P
><DIV
CLASS="PROCEDURE"
><OL
TYPE="1"
><LI
CLASS="STEP"
><P
>        GTM starts up normally, but now can accept connections from
        GTM proxies.
       </P
></LI
><LI
CLASS="STEP"
><P
>        GTM Proxy starts up. GTM Proxy creates GTM Proxy Threads. Each
        GTM Proxy Thread connects to the GTM in advance. The number of
        GTM Proxy Threads can be specified at the startup. A typical
        number of threads is one or two so it can save the number of
        connections between GTM and Coordinators.
       </P
></LI
><LI
CLASS="STEP"
><P
>        GTM Main Thread waits for the request connection from each
        backend.
       </P
></LI
></OL
></DIV
><P
>      When each Coordinator backend requests for connection, the Proxy
      Main Thread assigns a GTM Proxy Thread to handle
      request. Therefore, one GTM Proxy Thread handles multiple
      Coordinator backends. If a Coordinator has one hundred
      Coordinator backends and one GTM Proxy Thread, this thread takes
      care of one hundred Coordinator backend.
     </P
><P
>      Then GTM Proxy Thread scans all the requests from Coordinator
      backend. If Coordinator is busy, it is expected to capture
      more requests in a single scan. Therefore, the proxy can group
      many requests into single block of requests, to reduce the
      number of interaction between GTM and the Coordinator.
     </P
><P
>      Furthermore, in a single scan, we may have multiple request for
      snapshots. Because these requests can be regarded as received at
      the same time, we can represent multiple snapshots with single
      one. This will reduce the amount of data which GTM provides.
     </P
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="XC-OVERVIEW-COORDINATOR"
>49.2.4. Coordinator</A
></H2
><P
>     Coordinator handles SQL statements from applications and
     determines which Datanode should be involved and generates local
     SQL statements for each Datanode.  In the most simplest case, if
     a single Datanode is involved, the Coordinator simply proxies
     incoming statements to the Datanode.  In more complicated cases,
     for example, if the target Datanode cannot be determined, then
     the Coordinator generates local statements for each Datanode,
     collects the result to materialize at the Coordinator for further
     handling.  In this case, the Coordinator will try to optimize the
     plan by
     <P
></P
></P><UL
><LI
><P
>        Pushdown <TT
CLASS="COMMAND"
>WHERE</TT
> clause to Datanodes,
       </P
></LI
><LI
><P
>        Pushdown <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>joins</I
></SPAN
> to Datanodes,
       </P
></LI
><LI
><P
>        Pushdown <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>projection</I
></SPAN
> (column list in <TT
CLASS="COMMAND"
>SELECT</TT
> clause),
        </P
></LI
><LI
><P
>        Pushdown <TT
CLASS="COMMAND"
>ORDER BY</TT
> clause, as well as other clauses.
       </P
></LI
></UL
><P>

     If a transaction is involved by more than one Datanodes and/or
     Coordinators, the Coordinator will handle the transaction with
     two-phase commit protocol internally.
    </P
><P
>     In the case of aggregate
     functions, <SPAN
CLASS="PRODUCTNAME"
>Postgres-XL</SPAN
> introduced new
     function collection function between existing transition function
     and finalize function.  Collection function runs on the
     Coordinator to collect all the intermediate results from involved
     Datanodes.  For details, see <A
HREF="xaggr.html"
>Section 35.10</A
>
     and <A
HREF="sql-createaggregate.html"
>CREATE AGGREGATE</A
>.
    </P
><P
>     In the case of reading replicated tables, the Coordinator can choose
     any Datanode to read.  The most efficient way is to select one
     running in the same hardware or virtual machine.  This is
     called <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>preferred Datanode</I
></SPAN
> and can be
     specified by a GUC local to each Coordinator.
    </P
><P
>     On the other hand, in the case of writing replicated tables, all
     the Coordinators choose the same Datanode to begin with to avoid
     update conflicts.  This is called <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>primary
     Datanode</I
></SPAN
>.
    </P
><P
>     Coordinators also take care of DDL statements.  Because DDL
     statements handles system catalogs, which are replicated in all
     the Coordinators and Datanodes, they are proxied to all the
     Coordinators and Datanodes.  To synchronize the catalog update in
     all the nodes, the Coordinator handles DDL with two-phase commit
     protocol internally.
    </P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="XC-OVERVIEW-DATANODE"
>49.2.5. Datanode</A
></H2
><P
>     While Coordinators handle cluster-wide SQL statements, Datanodes
     take care of just local issues.  In this sense, Datanodes are
     essentially <SPAN
CLASS="PRODUCTNAME"
>PostgreSQL</SPAN
> servers except
     that transaction management information is obtained from GTM, as
     well as other global value.
    </P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="XC-OVERVIEW-POOLER"
>49.2.6. Coordinator And Datanode Connection</A
></H2
><P
>     The number of connections between Coordinators and Datanodes may
     increase from time to time. This may leave unused connection and
     waste system resources. Repeating real connect and disconnect
     requires Datanode backend initialization which increases latency
     and also wastes system resources.
    </P
><P
>     For example, as in the case of GTM, if each Coordinator has one
     hundred connections to applications and we have ten Coordinators,
     after a while, each Coordinator may have connection to each data
     node. It means that each Coordinator backend has ten connections
     to Coordinators and each Coordinator has one thousand (10 x 10)
     connections to Coordinators.
    </P
><P
>     Because we consume much more resources for locks and other
     control information per backend and only a few of such connection
     is active at a given time, it is not a good idea to hold such
     unused connections between Coordinator and Datanode.
    </P
><P
>     To improve this, Postgres-XL is equipped with connection pooler
     between Coordinator and Datanode. When a Coordinator backend
     requires connection to a Datanode, the pooler looks for
     appropriate connection from the pool. If there's an available
     one, the pooler assigns it to the Coordinator backend. When the
     connection is no longer needed, the Coordinator backend returns
     the connection to the pooler. The pooler does not disconnect the
     connection.  It keeps the connection to the pool for later reuse,
     keeping Datanode backend running.
    </P
></DIV
></DIV
><H3
CLASS="FOOTNOTES"
>Notes</H3
><TABLE
BORDER="0"
CLASS="FOOTNOTES"
WIDTH="100%"
><TR
><TD
ALIGN="LEFT"
VALIGN="TOP"
WIDTH="5%"
><A
NAME="FTN.AEN102604"
HREF="xc-overview-gtm.html#AEN102604"
><SPAN
CLASS="footnote"
>[1]</SPAN
></A
></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
WIDTH="95%"
><P
>       More precisely, XID is 32bit integer. When XID reaches the max
       value, it wraps around to the lowest value (3, as to the latest
       definition). PostgreSQL has a means to handle this, as well as
       Postgres-XL. For simplicity, it will not be described in this
       document.
      </P
></TD
></TR
><TR
><TD
ALIGN="LEFT"
VALIGN="TOP"
WIDTH="5%"
><A
NAME="FTN.AEN102606"
HREF="xc-overview-gtm.html#AEN102606"
><SPAN
CLASS="footnote"
>[2]</SPAN
></A
></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
WIDTH="95%"
><P
>       This description is somewhat simplified for explanation. You
       will find the precise rule in <TT
CLASS="FILENAME"
>tqual.c</TT
> file
       in PostgreSQL's source code.
      </P
></TD
></TR
></TABLE
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
SUMMARY="Footer navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="xc-overview-components.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="index.html"
ACCESSKEY="H"
>Home</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="catalogs.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><SPAN
CLASS="PRODUCTNAME"
>Postgres-XL</SPAN
> Components</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="xc-overview.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>System Catalogs</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>